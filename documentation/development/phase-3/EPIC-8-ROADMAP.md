# Phase 3: Epic 8 - Advanced AI Content Intelligence

**Date Started**: 2025-10-02
**Status**: In Progress
**Priority**: HIGH

---

## Overview

Epic 8 focuses on evolving JDDB from a document management tool into an intelligent workforce platform with advanced AI capabilities for content generation, quality analysis, bias detection, and predictive analytics.

---

## Current State Analysis

### âœ… Already Implemented (Phase 2)

**Backend Services**:
- `AIEnhancementService` (`backend/src/jd_ingestion/services/ai_enhancement_service.py`)
  - Text improvement suggestions (grammar, style, clarity)
  - Basic bias detection (gender pronouns)
  - Compliance checking framework (Treasury Board, accessibility, bilingual)
  - Template generation foundation
  - OpenAI integration structure

**API Endpoints** (`backend/src/jd_ingestion/api/endpoints/ai_suggestions.py`):
- `POST /api/ai/suggest-improvements` - Text enhancement suggestions
- `POST /api/ai/check-compliance` - Government standards compliance checking
- `POST /api/ai/analyze-bias` - Bias and inclusivity analysis
- `GET /api/ai/templates/{classification}` - Get template by classification
- `POST /api/ai/templates/generate` - Generate custom templates

**What Works**:
- Basic grammar checking (double spaces, etc.)
- Passive voice detection
- Long sentence identification
- Gender pronoun bias detection
- Quality scoring framework
- Template structure generation

**Gaps & Limitations**:
- Placeholder implementations for many features
- OpenAI integration not fully utilized
- Limited bias detection patterns
- No readability scoring
- No content quality metrics
- Missing predictive analytics
- No "source-to-post" generation

---

## Epic 8 Feature Breakdown

### ðŸŽ¯ Feature 1: Enhanced Bias Detection & De-biasing

**Current State**: Basic gender pronoun detection only
**Target State**: Comprehensive bias detection across multiple dimensions

#### Implementation Tasks

##### 1.1 Age Bias Detection (HIGH PRIORITY)
- [ ] Detect age-related terms ("young," "energetic," "digital native," "recent graduate")
- [ ] Flag experience requirements that may discriminate ("20+ years experience")
- [ ] Identify retirement-related language
- [ ] Provide neutral alternatives

**Files to Modify**:
- `backend/src/jd_ingestion/services/ai_enhancement_service.py:380-382`

**Pattern Library** (to implement):
```python
AGE_BIAS_PATTERNS = {
    "young": {
        "alternatives": ["collaborative", "innovative"],
        "severity": "high",
        "explanation": "Implies age discrimination"
    },
    "energetic": {
        "alternatives": ["motivated", "proactive"],
        "severity": "medium",
        "explanation": "May discourage older applicants"
    },
    "digital native": {
        "alternatives": ["tech-savvy", "digitally fluent"],
        "severity": "high",
        "explanation": "Excludes experienced professionals"
    },
    "recent graduate": {
        "alternatives": ["entry-level", "early career"],
        "severity": "medium",
        "explanation": "Suggests age preference"
    }
}
```

##### 1.2 Disability Bias Detection (HIGH PRIORITY)
- [ ] Detect ability-based language ("walk," "see," "hear" in requirements)
- [ ] Flag physical requirements that may exclude
- [ ] Identify ableist assumptions
- [ ] Suggest inclusive alternatives

**Pattern Library**:
```python
DISABILITY_BIAS_PATTERNS = {
    "must be able to stand": {
        "alternatives": ["position may involve standing"],
        "severity": "high",
        "explanation": "Excludes candidates with mobility impairments"
    },
    "excellent vision": {
        "alternatives": ["attention to detail with accommodation"],
        "severity": "high",
        "explanation": "Discriminatory requirement"
    },
    "must have driver's license": {
        "alternatives": ["reliable transportation required"],
        "severity": "medium",
        "explanation": "May exclude those unable to drive"
    }
}
```

##### 1.3 Cultural & Socioeconomic Bias (MEDIUM PRIORITY)
- [ ] Detect cultural assumptions ("North American experience")
- [ ] Flag socioeconomic barriers ("own laptop," "home office")
- [ ] Identify language that may exclude newcomers
- [ ] Provide inclusive alternatives

##### 1.4 Gender Bias Enhancement (HIGH PRIORITY)
Expand beyond basic pronouns:
- [ ] Detect gendered job titles ("salesman," "chairman")
- [ ] Identify masculine-coded language ("competitive," "dominant," "aggressive")
- [ ] Detect feminine-coded language ("supportive," "nurturing," "collaborative")
- [ ] Balance gendered language for neutral tone

**Enhanced Gender Pattern Library**:
```python
GENDERED_JOB_TITLES = {
    "chairman": ["chairperson", "chair"],
    "salesman": ["salesperson", "sales representative"],
    "policeman": ["police officer"],
    "fireman": ["firefighter"],
    "spokesman": ["spokesperson"]
}

MASCULINE_CODED_WORDS = [
    "competitive", "dominant", "aggressive", "assertive",
    "independent", "analytical", "leader"
]

FEMININE_CODED_WORDS = [
    "collaborative", "supportive", "nurturing", "interpersonal",
    "empathetic", "team player", "helper"
]
```

##### 1.5 AI-Powered Bias Detection (MEDIUM PRIORITY)
- [ ] Integrate OpenAI for context-aware bias detection
- [ ] Use GPT to analyze subtle biases
- [ ] Generate contextual alternatives
- [ ] Learn from user feedback

**Implementation**:
```python
async def _get_ai_bias_analysis(self, text: str) -> List[Dict[str, Any]]:
    """Use GPT-4 for advanced bias detection."""
    prompt = f"""Analyze the following job description text for potential bias.
    Focus on: age, gender, disability, cultural, and socioeconomic bias.

    Text: {text}

    Return JSON array of issues found with:
    - type (age/gender/disability/cultural/socioeconomic)
    - problematic_text (exact phrase)
    - explanation (why it's problematic)
    - suggested_alternatives (array of better options)
    - severity (high/medium/low)
    """

    response = await self.client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}],
        response_format={"type": "json_object"}
    )

    return json.loads(response.choices[0].message.content)
```

**Effort**: 5-7 days
**Priority**: P0 - Critical for inclusivity

---

### ðŸŽ¯ Feature 2: Content Quality Scoring

**Current State**: Simple penalty-based scoring
**Target State**: Comprehensive multi-dimensional quality assessment

#### Implementation Tasks

##### 2.1 Readability Scoring (HIGH PRIORITY)
- [ ] Implement Flesch Reading Ease score
- [ ] Calculate Flesch-Kincaid Grade Level
- [ ] SMOG (Simple Measure of Gobbledygook) index
- [ ] Target: Grade 8-10 reading level for accessibility

**Implementation**:
```python
def _calculate_readability_scores(self, text: str) -> Dict[str, float]:
    """Calculate multiple readability metrics."""
    import textstat

    return {
        "flesch_reading_ease": textstat.flesch_reading_ease(text),
        "flesch_kincaid_grade": textstat.flesch_kincaid_grade(text),
        "smog_index": textstat.smog_index(text),
        "automated_readability_index": textstat.automated_readability_index(text),
        "target_reading_level": 10.0,  # Grade 10
        "meets_target": textstat.flesch_kincaid_grade(text) <= 10.0
    }
```

**Dependencies**: Add `textstat` library
```bash
cd backend && poetry add textstat
```

##### 2.2 Completeness Scoring (HIGH PRIORITY)
- [ ] Check for required sections (accountability, qualifications, structure)
- [ ] Verify minimum content length per section
- [ ] Flag missing critical information
- [ ] Score based on section coverage

**Implementation**:
```python
def _calculate_completeness_score(self, job_data: Dict) -> Dict[str, Any]:
    """Score based on section completeness."""
    required_sections = [
        "general_accountability",
        "organization_structure",
        "key_responsibilities",
        "qualifications"
    ]

    present_sections = [s for s in required_sections if job_data.get(s)]
    completeness = len(present_sections) / len(required_sections)

    # Check minimum content length (100 words per section)
    adequate_content = sum(
        1 for section in present_sections
        if len(job_data[section].split()) >= 100
    )

    content_quality = adequate_content / len(required_sections)

    return {
        "completeness_score": completeness,
        "content_adequacy_score": content_quality,
        "overall_completeness": (completeness + content_quality) / 2,
        "missing_sections": [s for s in required_sections if s not in present_sections]
    }
```

##### 2.3 Clarity & Structure Scoring (MEDIUM PRIORITY)
- [ ] Analyze sentence structure variety
- [ ] Check paragraph length consistency
- [ ] Detect excessive jargon
- [ ] Score logical flow and organization

##### 2.4 Compliance Scoring (MEDIUM PRIORITY)
- [ ] Treasury Board directive compliance (10 points)
- [ ] Bilingual requirements (10 points)
- [ ] Accessibility standards (10 points)
- [ ] Inclusive language (10 points)

##### 2.5 Overall Quality Score (HIGH PRIORITY)
Combine all metrics into final score:

**Formula**:
```
Overall Quality = (
    Readability * 0.20 +
    Completeness * 0.25 +
    Clarity * 0.15 +
    Inclusivity * 0.20 +
    Compliance * 0.20
) * 100

Result: Score from 0-100
- 90-100: Excellent
- 75-89: Good
- 60-74: Fair
- Below 60: Needs Improvement
```

**Effort**: 4-5 days
**Priority**: P0 - Core feature for quality assurance

---

### ðŸŽ¯ Feature 3: Intelligent Content Generation

**Current State**: Basic template structure only
**Target State**: AI-powered context-aware content generation

#### Implementation Tasks

##### 3.1 Section Auto-Completion (HIGH PRIORITY)
- [ ] Generate section content based on classification and title
- [ ] Use GPT-4 with job description examples as context
- [ ] Maintain government standards compliance
- [ ] Support EN/FR generation

**Implementation**:
```python
async def generate_section_content(
    self,
    section_type: str,
    classification: str,
    title: str,
    language: str = "en"
) -> str:
    """Generate section content using AI."""

    # Get similar job examples for context
    examples = await self._get_similar_job_examples(classification)

    prompt = f"""Generate a {section_type} section for a Government of Canada job description.

Classification: {classification}
Job Title: {title}
Language: {language}

Requirements:
- Follow Treasury Board standards
- Use clear, accessible language (Grade 8-10 reading level)
- Be inclusive and bias-free
- Match the style of these examples:

{examples}

Generate the {section_type} section:"""

    response = await self.client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.7,
        max_tokens=500
    )

    return response.choices[0].message.content
```

##### 3.2 Smart Section Suggestions (MEDIUM PRIORITY)
- [ ] Analyze context and suggest missing sections
- [ ] Recommend section expansions
- [ ] Suggest competency requirements
- [ ] Provide related content ideas

##### 3.3 Content Enhancement (MEDIUM PRIORITY)
- [ ] Rewrite passive voice to active
- [ ] Simplify complex sentences
- [ ] Enhance clarity while maintaining meaning
- [ ] Adjust tone and formality

**Effort**: 5-6 days
**Priority**: P1 - High value for users

---

### ðŸŽ¯ Feature 4: "Source-to-Post" Job Posting Generation

**Current State**: Not implemented
**Target State**: Generate external-facing job postings from internal descriptions

#### Implementation Tasks

##### 4.1 Internal vs External Content Differentiation (HIGH PRIORITY)
- [ ] Identify internal-only sections (organization structure, reporting lines)
- [ ] Extract public-facing information (responsibilities, qualifications)
- [ ] Transform technical language to accessible language
- [ ] Add recruitment-focused content

##### 4.2 Job Posting Generator (HIGH PRIORITY)
- [ ] Create compelling job title
- [ ] Generate summary/hook (50-100 words)
- [ ] Extract key responsibilities (bullet points)
- [ ] List qualifications and requirements
- [ ] Add organization description
- [ ] Include application instructions

**Implementation**:
```python
async def generate_external_posting(
    self,
    job_description_id: int,
    target_platform: str = "gc_jobs"  # gc_jobs, linkedin, etc.
) -> Dict[str, Any]:
    """Generate external job posting from internal JD."""

    # Fetch internal job description
    job = await self._get_job_by_id(job_description_id)

    prompt = f"""Transform this internal Government of Canada job description into
an engaging external job posting for {target_platform}.

Internal Job Description:
Title: {job.title}
Classification: {job.classification}
Accountabilities: {job.general_accountability}
Responsibilities: {job.key_responsibilities}
Qualifications: {job.qualifications}

Create an external posting with:
1. Compelling title (different from internal if needed)
2. Engaging summary (50-100 words) that attracts candidates
3. Key responsibilities (5-7 bullet points)
4. Must-have qualifications
5. Nice-to-have qualifications
6. Why join this team (selling points)

Style: Professional yet approachable, inclusive, exciting"""

    response = await self.client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.8,  # More creative
        max_tokens=800
    )

    posting = self._parse_posting_response(response.choices[0].message.content)

    return {
        "posting_id": str(uuid.uuid4()),
        "source_job_id": job_description_id,
        "platform": target_platform,
        "title": posting["title"],
        "summary": posting["summary"],
        "responsibilities": posting["responsibilities"],
        "must_have_qualifications": posting["must_have"],
        "nice_to_have_qualifications": posting["nice_to_have"],
        "selling_points": posting["why_join"],
        "generated_at": datetime.utcnow().isoformat()
    }
```

##### 4.3 Platform-Specific Optimization (LOW PRIORITY)
- [ ] GC Jobs format and requirements
- [ ] LinkedIn optimization
- [ ] Indeed formatting
- [ ] Character limit compliance

**Effort**: 4-5 days
**Priority**: P1 - High business value

---

### ðŸŽ¯ Feature 5: Predictive Content Analytics

**Current State**: Not implemented
**Target State**: Predictive insights and recommendations

#### Implementation Tasks

##### 5.1 Application Volume Prediction (MEDIUM PRIORITY)
- [ ] Analyze historical data correlation
- [ ] Predict application volume based on:
  - Classification level
  - Job title keywords
  - Requirements specificity
  - Language used
- [ ] Provide optimization suggestions

##### 5.2 Time-to-Fill Estimation (MEDIUM PRIORITY)
- [ ] Predict hiring timeline based on:
  - Classification complexity
  - Qualification requirements
  - Market demand
- [ ] Suggest ways to accelerate

##### 5.3 Competitive Benchmarking (LOW PRIORITY)
- [ ] Compare against similar roles
- [ ] Analyze market standards
- [ ] Identify gaps and opportunities
- [ ] Recommend competitive advantages

**Effort**: 6-8 days (requires historical data analysis)
**Priority**: P2 - Strategic value, lower urgency

---

## Frontend Integration Tasks

### New Components Needed

#### 1. AI Suggestions Panel (`src/components/ai/AISuggestionsPanel.tsx`)
- Display real-time AI suggestions as user types
- Show bias detection alerts
- Present quality score with breakdown
- Allow accept/reject actions

#### 2. Quality Dashboard (`src/components/ai/QualityDashboard.tsx`)
- Visual quality score (0-100 with color coding)
- Breakdown by dimension (readability, completeness, etc.)
- Trend over time
- Comparison to benchmarks

#### 3. Bias Detector Widget (`src/components/ai/BiasDetector.tsx`)
- Highlight biased text inline
- Show severity indicators
- Provide one-click replacements
- Track bias reduction progress

#### 4. Content Generator Modal (`src/components/ai/ContentGenerator.tsx`)
- Section auto-complete interface
- Template selection
- Customization options
- Preview and refine

#### 5. Job Posting Generator (`src/components/ai/PostingGenerator.tsx`)
- Transform internal JD to external posting
- Platform selection (GC Jobs, LinkedIn, etc.)
- Preview different formats
- Export functionality

### API Client Integration (`src/lib/api.ts`)
```typescript
// Add AI-related methods
async analyzeBias(text: string): Promise<BiasAnalysisResponse> {
  return this.post('/ai/analyze-bias', { text });
}

async getSuggestions(text: string): Promise<SuggestionsResponse> {
  return this.post('/ai/suggest-improvements', { text });
}

async generateSectionContent(params: SectionGenerationParams): Promise<string> {
  return this.post('/ai/generate-section', params);
}

async generateJobPosting(jobId: number, platform: string): Promise<PostingResponse> {
  return this.post('/ai/generate-posting', { jobId, platform });
}

async getQualityScore(jobId: number): Promise<QualityScoreResponse> {
  return this.get(`/ai/quality-score/${jobId}`);
}
```

**Effort**: 8-10 days frontend work
**Priority**: P1 - Essential for user experience

---

## Implementation Roadmap

### Week 1-2: Enhanced Bias Detection & Quality Scoring
**Focus**: Core AI intelligence features

- [ ] Day 1-3: Implement comprehensive bias detection patterns
  - Age bias patterns and detection
  - Disability bias patterns
  - Enhanced gender bias
  - Cultural/socioeconomic bias

- [ ] Day 4-5: Implement readability scoring
  - Add textstat library
  - Calculate Flesch scores
  - Set target thresholds

- [ ] Day 6-7: Implement completeness and quality scoring
  - Section completeness checker
  - Content adequacy scoring
  - Overall quality formula

- [ ] Day 8-10: Testing and refinement
  - Test with sample job descriptions
  - Calibrate scoring thresholds
  - Validate bias detection accuracy

**Deliverables**:
- Enhanced `AIEnhancementService` with comprehensive bias detection
- Quality scoring implementation
- Updated API endpoints
- Unit tests

### Week 3-4: Intelligent Content Generation
**Focus**: AI-powered content creation

- [ ] Day 11-13: Section auto-completion
  - Implement GPT-4 integration for content generation
  - Create prompt templates
  - Add context from similar jobs

- [ ] Day 14-16: Content enhancement features
  - Active voice transformation
  - Sentence simplification
  - Tone adjustment

- [ ] Day 17-19: Smart suggestions
  - Missing section detection
  - Expansion recommendations
  - Related content ideas

- [ ] Day 20: Integration testing

**Deliverables**:
- Content generation endpoints
- AI prompt library
- Enhanced template service

### Week 5-6: Source-to-Post & Frontend Integration
**Focus**: Job posting generation and UI

- [ ] Day 21-23: Job posting generator
  - Internal to external transformation
  - Platform-specific formatting
  - Optimization suggestions

- [ ] Day 24-30: Frontend components
  - AI Suggestions Panel
  - Quality Dashboard
  - Bias Detector Widget
  - Content Generator Modal
  - Job Posting Generator

**Deliverables**:
- Job posting generation feature
- Complete frontend AI integration
- User documentation

### Week 7-8: Predictive Analytics & Polish
**Focus**: Advanced features and refinement

- [ ] Day 31-35: Predictive analytics (if time permits)
  - Application volume prediction
  - Time-to-fill estimation
  - Competitive benchmarking

- [ ] Day 36-40: Polish and optimization
  - Performance optimization
  - User feedback incorporation
  - Documentation completion
  - Demo preparation

**Deliverables**:
- Predictive analytics (optional)
- Complete documentation
- User training materials

---

## Success Metrics

### Technical Metrics
- **API Response Time**: < 2 seconds for AI suggestions
- **Accuracy**: 90%+ bias detection accuracy
- **Coverage**: Detect 95%+ of common bias patterns
- **Quality**: Generated content passes 80%+ quality threshold

### Business Metrics
- **Adoption**: 60%+ of users try AI features within first week
- **Usage**: Average 5+ AI suggestions accepted per job description
- **Quality Improvement**: 20% increase in average quality scores
- **Time Savings**: 30% reduction in job description creation time

### User Satisfaction
- **Feature Rating**: 4.0+ stars (out of 5)
- **NPS Score**: 40+ (Net Promoter Score)
- **Feature Requests**: AI features in top 3 most requested enhancements

---

## Dependencies

### Backend Dependencies
```toml
# Add to backend/pyproject.toml
textstat = "^0.7.3"          # Readability scoring
openai = "^1.0.0"            # Already present, ensure latest
spacy = "^3.7.0"             # NLP for advanced text analysis (optional)
language-tool-python = "^2.8" # Grammar checking (optional)
```

### Frontend Dependencies
```json
// Add to package.json
"recharts": "^2.10.0",        // Quality score visualizations
"react-markdown": "^9.0.0",   // Render AI suggestions
"diff": "^5.1.0"              // Show text differences
```

### External Services
- **OpenAI API**: GPT-4 access required (costs ~$0.03 per 1K tokens)
- **Budget Estimate**: $200-500/month for moderate usage

---

## Risk Mitigation

### Risk 1: OpenAI API Costs
**Mitigation**:
- Implement request caching
- Rate limiting per user
- Fallback to rule-based detection
- Monthly budget caps

### Risk 2: AI Accuracy Issues
**Mitigation**:
- Human review required for critical suggestions
- Confidence scores on all recommendations
- User feedback loop for improvement
- Gradual rollout with beta testing

### Risk 3: Performance Concerns
**Mitigation**:
- Async processing for large documents
- Background job processing with Celery
- Result caching
- Progressive loading of suggestions

---

## Next Steps

1. **Immediate** (This Week):
   - [ ] Install textstat dependency
   - [ ] Implement enhanced bias detection patterns
   - [ ] Create quality scoring algorithm

2. **Short Term** (Next 2 Weeks):
   - [ ] Complete content quality scoring
   - [ ] Build AI content generation
   - [ ] Create frontend components

3. **Medium Term** (Next 4-6 Weeks):
   - [ ] Job posting generator
   - [ ] Predictive analytics
   - [ ] Full user testing

---

**Document Owner**: Development Team
**Last Updated**: 2025-10-02
**Review Schedule**: Weekly during active development
